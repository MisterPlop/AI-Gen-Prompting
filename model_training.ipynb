{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger le CSV, importer et supprimer les colonnes spécifiées\n",
    "# Prompt : \n",
    "# read the file \"avocado.csv\", \n",
    "# strip the columns : \"Unnamed: 0, Total Volume, and Total Bags\" \n",
    "# and put it inside a dataframe named \"df_avocado\"\n",
    "\n",
    "# Read the CSV file\n",
    "import pandas as pd\n",
    "\n",
    "# Read the file and create the dataframe\n",
    "df_avocado = pd.read_csv('avocado.csv')\n",
    "\n",
    "# Drop the specified columns\n",
    "columns_to_drop = ['Unnamed: 0', 'Total Volume', 'Total Bags']\n",
    "df_avocado = df_avocado.drop(columns=columns_to_drop, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renommage de colonnes\n",
    "## Prompt :\n",
    "# inside the dataframe df_avocado, rename the columns, \n",
    "# respectively, \"4046, 4225, 4770\" to \"Quality1, Quality2, and Quality3\"\n",
    "# please use the inplace parameter if possible to reuse the df\n",
    "\n",
    "# Rename the columns\n",
    "column_mapping = {\n",
    "    '4046': 'Quality1',\n",
    "    '4225': 'Quality2',\n",
    "    '4770': 'Quality3'\n",
    "}\n",
    "df_avocado.rename(columns=column_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les dates\n",
    "##Prompt\n",
    "#Inside df_avocado, the column \"Date\" must be converted in python usable \"datetime\" format\n",
    "\n",
    "# Convert Date column to datetime\n",
    "df_avocado['Date'] = pd.to_datetime(df_avocado['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucune valeur manquante!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##Prompt : \n",
    "# run through the rows of df_avocado, \n",
    "# if a row is a duplicate, drop it. \n",
    "# If a value is missing inside the row, put the row ID inside a var named \"inconsistent_rows_array\"\n",
    "# If no row was inconsistent, display \"Aucune valeur manquante!\". \n",
    "# Else, display the array of inconsistent rows preceded by \"Index des lignes avec des valeurs manquantes :\"\n",
    "\n",
    "# Check for duplicates and missing values\n",
    "# Drop duplicates\n",
    "df_avocado.drop_duplicates(inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "inconsistent_rows_array = df_avocado[df_avocado.isnull().any(axis=1)].index.tolist()\n",
    "\n",
    "if len(inconsistent_rows_array) == 0:\n",
    "    print(\"Aucune valeur manquante!\")\n",
    "else:\n",
    "    print(\"Index des lignes avec des valeurs manquantes :\")\n",
    "    print(inconsistent_rows_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sépération des colonnes numériques et catégoriques\n",
    "##Prompt\n",
    "#Create a new dataframe, from df_avocado, named df_avocado_num, \n",
    "# containing the following rows :  Quality1, Quality2, Quality3, Small Bags, Large Bags, XLarge Bags, year. \n",
    "# Then, create a new dataframe, also from df_avocado, named df_avocado_cat, containing : type, region\n",
    "\n",
    "# Create numeric and categorical dataframes\n",
    "numeric_columns = ['Quality1', 'Quality2', 'Quality3', 'Small Bags', 'Large Bags', 'XLarge Bags', 'year']\n",
    "categorical_columns = ['type', 'region']\n",
    "\n",
    "df_avocado_num = df_avocado[numeric_columns].copy()\n",
    "df_avocado_cat = df_avocado[categorical_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalisation des données\n",
    "##Prompt\n",
    "# Normalize the values inside df_avocado_num using StandardScaler; put the results inside df_avocado_num_scaled, \n",
    "# make imports if necessary\n",
    "\n",
    "# Normalize numeric values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_avocado_num_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(df_avocado_num),\n",
    "    columns=df_avocado_num.columns,\n",
    "    index=df_avocado_num.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      type_organic  region_Atlanta  region_BaltimoreWashington  region_Boise  \\\n",
      "9123           0.0             0.0                         0.0           0.0   \n",
      "9124           0.0             0.0                         0.0           0.0   \n",
      "9125           0.0             0.0                         0.0           0.0   \n",
      "9126           1.0             0.0                         0.0           0.0   \n",
      "9127           1.0             0.0                         0.0           0.0   \n",
      "9128           1.0             0.0                         0.0           0.0   \n",
      "9129           1.0             0.0                         0.0           0.0   \n",
      "9130           1.0             0.0                         0.0           0.0   \n",
      "\n",
      "      region_Boston  region_BuffaloRochester  region_California  \\\n",
      "9123            0.0                      0.0                0.0   \n",
      "9124            0.0                      0.0                0.0   \n",
      "9125            0.0                      0.0                0.0   \n",
      "9126            0.0                      0.0                0.0   \n",
      "9127            0.0                      0.0                0.0   \n",
      "9128            0.0                      0.0                0.0   \n",
      "9129            0.0                      0.0                0.0   \n",
      "9130            0.0                      0.0                0.0   \n",
      "\n",
      "      region_Charlotte  region_Chicago  region_CincinnatiDayton  ...  \\\n",
      "9123               0.0             0.0                      0.0  ...   \n",
      "9124               0.0             0.0                      0.0  ...   \n",
      "9125               0.0             0.0                      0.0  ...   \n",
      "9126               0.0             0.0                      0.0  ...   \n",
      "9127               0.0             0.0                      0.0  ...   \n",
      "9128               0.0             0.0                      0.0  ...   \n",
      "9129               0.0             0.0                      0.0  ...   \n",
      "9130               0.0             0.0                      0.0  ...   \n",
      "\n",
      "      region_SouthCarolina  region_SouthCentral  region_Southeast  \\\n",
      "9123                   0.0                  0.0               0.0   \n",
      "9124                   0.0                  0.0               0.0   \n",
      "9125                   0.0                  0.0               0.0   \n",
      "9126                   0.0                  0.0               0.0   \n",
      "9127                   0.0                  0.0               0.0   \n",
      "9128                   0.0                  0.0               0.0   \n",
      "9129                   0.0                  0.0               0.0   \n",
      "9130                   0.0                  0.0               0.0   \n",
      "\n",
      "      region_Spokane  region_StLouis  region_Syracuse  region_Tampa  \\\n",
      "9123             0.0             0.0              0.0           0.0   \n",
      "9124             0.0             0.0              0.0           0.0   \n",
      "9125             0.0             0.0              0.0           0.0   \n",
      "9126             0.0             0.0              0.0           0.0   \n",
      "9127             0.0             0.0              0.0           0.0   \n",
      "9128             0.0             0.0              0.0           0.0   \n",
      "9129             0.0             0.0              0.0           0.0   \n",
      "9130             0.0             0.0              0.0           0.0   \n",
      "\n",
      "      region_TotalUS  region_West  region_WestTexNewMexico  \n",
      "9123             0.0          0.0                      1.0  \n",
      "9124             0.0          0.0                      1.0  \n",
      "9125             0.0          0.0                      1.0  \n",
      "9126             0.0          0.0                      0.0  \n",
      "9127             0.0          0.0                      0.0  \n",
      "9128             0.0          0.0                      0.0  \n",
      "9129             0.0          0.0                      0.0  \n",
      "9130             0.0          0.0                      0.0  \n",
      "\n",
      "[8 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "# Encodage des données catégoriques\n",
    "## Prompt\n",
    "# Use a OneHotEncoder to transform the categorical data into numerical datan use \"drop first\" and \"handle unknown ignore\" as parameters\n",
    "# Display the rows 9123 to 9130 to verify the changes\n",
    "\n",
    "# One-hot encode categorical data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "encoder = OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False)\n",
    "encoded_data = encoder.fit_transform(df_avocado_cat)\n",
    "\n",
    "# Create DataFrame with encoded categorical data\n",
    "feature_names = encoder.get_feature_names_out(categorical_columns)\n",
    "df_avocado_cat_scaled = pd.DataFrame(\n",
    "    encoded_data,\n",
    "    columns=feature_names,\n",
    "    index=df_avocado_cat.index\n",
    ")\n",
    "\n",
    "# Display specified rows\n",
    "print(df_avocado_cat_scaled.iloc[9123:9131])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner les dataframes scalés\n",
    "## Prompt\n",
    "# Using ColumnTransformer, encoder and scaler\n",
    "# apply the required changes to the scaled dataframes, df_avocado_num_scaled and df_avocado_cat_scaled, \n",
    "# to create a new dataframe called df_avocado_transformed. \n",
    "# Make imports if necessary. \n",
    "\n",
    "# Apply ColumnTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create the final transformed dataframe\n",
    "df_avocado_transformed = pd.concat([df_avocado_num_scaled, df_avocado_cat_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un pipeline\n",
    "## Prompt\n",
    "# Create a new pipeline, including : \n",
    "# pretreatement of data using ColumnTransformer, \n",
    "# a prediction model based off XGBRegressor\n",
    "\n",
    "# Create pipeline with ColumnTransformer and XGBRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define transformers\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des données\n",
    "## Prompt\n",
    "# We want to predict the average price of avocados, using all available data.\n",
    "# Use the df_avocado_transformed var exclusively, DO NOT use df_avocado\n",
    "# Split the data with : 80% of data to train, 20% remaining data to test and evaluate the model. \n",
    "# Target is AveragePrice. \n",
    "# Features are all the other data. Explicitly define them.\n",
    "# Use the train_test_split method from sklearn. random state of 1337. \n",
    "# Make imports if necessary\n",
    "\n",
    "# Prepare data for model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define target and features\n",
    "target = 'AveragePrice'\n",
    "features = numeric_columns + categorical_columns\n",
    "\n",
    "# Split the data\n",
    "X = df_avocado[features]\n",
    "y = df_avocado[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1337\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² score on training data: 0.9142\n"
     ]
    }
   ],
   "source": [
    "#Entrainement du modèle\n",
    "## Prompt\n",
    "# Train the pipeline model using the targets and feature X and y, including X_train, X_test, y_train, y_test\n",
    "# Display the R² score\n",
    "# Train the model\n",
    "\n",
    "# Train the model and display R² score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate and display R² score\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "print(f\"R² score on training data: {train_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.1610\n",
      "R² score on test data: 0.8381\n"
     ]
    }
   ],
   "source": [
    "# Prédictions et évaluation\n",
    "## Prompt\n",
    "# Predict the AveragePrice from the whole test dataset\n",
    "# Evaluate the model using 2 key metrics : RMSE and R²\n",
    "# Make imports if necessary\n",
    "\n",
    "# Predict and evaluate model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions on test set\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Calculate R²\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R² score on test data: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline saved successfully as 'avocado_price_predictor.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Export de la pipeline\n",
    "## Prompt\n",
    "# Save the whole pipeline inside a .pkl file for future usage outside of this environment, no future training required.\n",
    "# Make imports if necessary\n",
    "\n",
    "# Save the pipeline\n",
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "with open('avocado_price_predictor.pkl', 'wb') as file:\n",
    "    pickle.dump(pipeline, file)\n",
    "\n",
    "print(\"Pipeline saved successfully as 'avocado_price_predictor.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
